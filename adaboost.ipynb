{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: SergioSJS\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from random import seed, randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dicX = {'o': 0.0, 'x' : 1.0, 'b' : -1.0}\n",
    "dicY = {'negative' : -1, 'positive' : 1}\n",
    "\n",
    "def replace(data, dic):\n",
    "    ndata = np.zeros(data.shape)\n",
    "    for r, row in enumerate(data):\n",
    "        for c, col in enumerate(row):\n",
    "            ndata[r, c] = dic.get(col)\n",
    "    return ndata\n",
    "\n",
    "def print_tic_tac_toe(tup):\n",
    "    line = ''\n",
    "    for l, it in enumerate(tup):\n",
    "        line = line + ' ' + it\n",
    "        if (l+1) % 3 == 0:\n",
    "            print line\n",
    "            line = ''\n",
    "            \n",
    "def kfold(data, folds=5):\n",
    "    data_splited = list()\n",
    "    data_copy = list(range(len(data)))\n",
    "    fold_size = int(len(data)/folds)\n",
    "    \n",
    "\n",
    "       \n",
    "    for i in range(folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(data_copy))\n",
    "            fold.append(data_copy.pop(index))\n",
    "        data_splited.append(fold)\n",
    "    \n",
    "    for i in range(folds):\n",
    "        test_list = list()\n",
    "        train_list = list()\n",
    "        train_temp = list()\n",
    "        \n",
    "        rangeF = range(folds)\n",
    "        rangeF.pop(i)\n",
    "        for i2 in rangeF:\n",
    "            train_temp.append(data_splited[i2])\n",
    "            \n",
    "        train_list.append([y for x in train_temp for y in x])\n",
    "        test_list.append(data_splited[i]) \n",
    "    \n",
    "        yield train_list, test_list\n",
    "    \n",
    "            \n",
    "#Load data\n",
    "dataset = np.loadtxt('tic-tac-toe.data', delimiter=',', dtype=str)\n",
    "xData = dataset[:,0:-1]\n",
    "yData = dataset[:,-1:]\n",
    "\n",
    "n_xData = replace(xData, dicX)\n",
    "n_yData = replace(yData, dicY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DesicionStump():\n",
    "    def __init__(self, xData, yData):\n",
    "        self.xData = np.array(xData)\n",
    "        self.yData = np.array(yData)     \n",
    "        self.Qtd = self.xData.shape[1]\n",
    "        \n",
    "    def stump_train(self, W, steps=3, verbose=0):\n",
    "        minErr = float('inf')\n",
    "        _value = 0\n",
    "        _att = 0\n",
    "        _label = 0\n",
    "        self.W = np.array(W)\n",
    "        \n",
    "        for att in range(self.Qtd):\n",
    "            value, err = self._best_stump(att, steps, 1)\n",
    "            if (err < minErr):\n",
    "                minErr = err\n",
    "                _value = value\n",
    "                _att = att\n",
    "                _label = 1\n",
    "        for it in range(self.Qtd):\n",
    "            value, err = self._best_stump(att, steps, -1)\n",
    "            if (err < minErr):\n",
    "                minErr = err\n",
    "                _value = value\n",
    "                _att = att\n",
    "                _label = -1\n",
    "        \n",
    "        self.value = _value\n",
    "        self.att = _att\n",
    "        self.label = _label\n",
    "        \n",
    "        if verbose == 1:\n",
    "            print 'att.:',_att,'- value:',_value,'- label:',_label, '- minErr:', minErr\n",
    "        \n",
    "        return minErr\n",
    "            \n",
    "    def _best_stump(self, att, steps, label):\n",
    "        limite_up = np.max(self.xData[:, att])+1\n",
    "        limite_bottom = np.min(self.xData[:, att])\n",
    "        interval = (limite_up-limite_bottom)/steps\n",
    "        \n",
    "        _value = 0\n",
    "        _minErr = float('inf')\n",
    "        \n",
    "        for value in np.arange(limite_bottom, limite_up, interval):\n",
    "            # This code only considerate categorical data\n",
    "            predict = self._predict_categorical_train(att, value, label)\n",
    "            \n",
    "            err = 0\n",
    "            \n",
    "            for i, d in enumerate(self.yData):\n",
    "                err += (predict[i] != d) * self.W[i]\n",
    "                \n",
    "            if err < _minErr:\n",
    "                _minErr = err\n",
    "                _value = value\n",
    "        return _value, _minErr\n",
    "            \n",
    "    def _predict_categorical_train(self, att, value, label):\n",
    "        predict = np.zeros(self.yData.shape)\n",
    "        for id, x in enumerate(self.xData[:,att]):\n",
    "            if x == value:\n",
    "                predict[id] = 1*label\n",
    "            else:\n",
    "                predict[id] = -1*label       \n",
    "        return predict\n",
    "    \n",
    "    def predict_categorical(self, xTest):\n",
    "        xTest=np.array(xTest)\n",
    "        predict = np.zeros(xTest.shape[0])\n",
    "        for id, x in enumerate(xTest[:,self.att]):\n",
    "            if x == self.value:\n",
    "                predict[id] = 1*self.label\n",
    "            else:\n",
    "                predict[id] = -1*self.label       \n",
    "        return predict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost():\n",
    "    def __init__(self, xData, yData):\n",
    "        self.xData = np.array(xData)\n",
    "        self.yData = np.array(yData)\n",
    "        self.sums = np.zeros(self.yData.shape)\n",
    "        # Initialize weights\n",
    "        self.W = np.ones((self.xData.shape[0],1)).flatten()/self.xData.shape[0]\n",
    "\n",
    "        self.dStump = DesicionStump\n",
    "    \n",
    "    def train(self, M=5, verbose=0):\n",
    "        self.alpha = {}\n",
    "        self.models = {}\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        for i in range(M):\n",
    "            self.models[i] = self.dStump(self.xData, self.yData)\n",
    "            \n",
    "            e = self.models[i].stump_train(self.W, verbose = verbose)\n",
    "            self.alpha[i] = (1/2.)*np.log((1-e)/e)\n",
    "            res = self.models[i].predict_categorical(self.xData)\n",
    "            \n",
    "            Wz = self.W*np.exp(-self.alpha[i]*self.yData.flatten()*res.flatten())\n",
    "            \n",
    "            self.W = (Wz/Wz.sum()).flatten()\n",
    "            \n",
    "    def predict(self, testX):\n",
    "        testX = np.array(testX)\n",
    "        sums=np.zeros(testX.shape[0])\n",
    "        \n",
    "        for i in range(len(self.models)):\n",
    "            sums = sums+self.models[i].predict_categorical(testX).flatten()*self.alpha[i]\n",
    "               \n",
    "        prev_y=np.zeros(np.array(sums).shape)\n",
    "        prev_y[sums>=0]=1\n",
    "        prev_y[sums<0]=-1\n",
    "        \n",
    "        return prev_y\n",
    "        \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.973821989529\n",
      "acc 0.973821989529\n",
      "acc 0.989528795812\n",
      "acc 0.979057591623\n",
      "acc 0.984293193717\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "for train, test in kfold(n_yData):\n",
    "    ada = AdaBoost(n_xData[train], n_yData[train])\n",
    "    ada.train(1000, verbose = 0)\n",
    "    \n",
    "    aa = ada.predict(n_xData[test])\n",
    "\n",
    "    err = 0.\n",
    "    acc = 0.\n",
    "    for i, a in enumerate(n_yData[test]):\n",
    "        if a == aa[i]:\n",
    "            acc += 1\n",
    "        else:\n",
    "            err += 1\n",
    "        #print i, a, n_yData[i]\n",
    "    print \"acc\", acc/(acc+err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 = acc 0.746346555324\n",
    "200 = acc 0.80375782881\n",
    "500 = acc 0.903966597077\n",
    "1000 = acc 0.978079331942\n",
    "1500 = acc 0.983298538622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
